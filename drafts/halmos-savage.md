Halmos and Savage state that their paper is an attempt to build a theory of sufficient statistics that does not rely on familiar comforts such as random variables being in $\mathbb R^n$. Sufficient statistics are complicated and hard to understand already. Thus, H&S end up with a statement that is complicated, hard to understand, and full of unfamiliar objects and language. Let's break down the theorem into its component parts and give each one a tangible analog. 

The theorem is built on the following elements. 

 - a dominated statistical model $(\Omega, \mathscr A, \mathscr P)$. Here, "dominated" means "each measure in the set may be expressed as the indefinite integral of a density function with respect to a fixed measure which is not itself necessarily in the set." An example is the family of size-three samples from univariate Normal distributions with variance 1, which can each be expressed as the integral of a density function (the familiar $\frac{1}{\sqrt {2\pi V }}\exp(\frac{-(x-\mu^2)}{V})$, but cubed and with $V=1$) - with respect to the Lebesgue measure $dx$. 
 - a statistic $T: (\Omega, \mathscr A, \mathscr P)\to(\Omega', \mathscr A')$. This is simply a summary of the the data, for example $T(x) = \frac{1}{3}\sum_i x_i$.
 - a "privileged measure" $dP^*$ such that $P^*=\sum_{i=1}^\infty P_i c_i $ for $c_i >0, \sum_{i=1}^\infty c_i =1$ and $P_i \in \mathscr P$. This corresponds to the following sampling scheme: draw an integer $I$ with $Pr(I=i)=c_i$, then draw from $P_i$. It is a mixture distribution over members of the class of distributions under consideration. For my Gaussian example, it could just be the measure corresponding to the standard Normal distribution: $P^*(E) = \int_E \left[\frac{1}{\sqrt{2\pi}}\exp(-x^2) \right]^3dx $.
 - the Radon Nikodym derivative $\frac{dP}{dP^*}$, where $P$ is any member of the model we consider. This is a function $f$ such that $f dP^* = dP$, or more precisely $\int_E f dP^* = dP(E)$. For example, if $P$ is from a Gaussian with mean 2, $\frac{dP}{dP^*}$ would be $\frac{\exp(-(x-2)^2)}{\exp(-x^2)}$ (but then cubed).

Now, the key ingredient of the theorem is that $\frac{dP}{dP^*}$ must be $T$-measurable. How would we construct the correct $P^*$ for the example, where we know the sufficient statistic is the sample mean? Well, $\frac{dP}{dP^*}$ should be $T$-measurable. I will define $f\equiv\frac{dP}{dP^*}$ for readability. $\frac{dP}{dP^*}$ or $f$ is $T$-measurable if $f^-1()$

